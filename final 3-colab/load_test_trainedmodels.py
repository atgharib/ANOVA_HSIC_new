# -*- coding: utf-8 -*-
"""Load_test_trainedModels.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1qWhzMyiaHcLYJu_b2beiQ9kmWdo58dfp
"""

from google.colab import drive
drive.mount('/content/drive')

!ls /content/drive/My\ Drive/

# Commented out IPython magic to ensure Python compatibility.
# %cd /content/drive/My\ Drive/HSIC/
!ls  # Lists files in the current folder

!pip install sparsemax
!pip install ucimlrepo

import torch
import os
from real_datasets import load_dataset
from sklearn.model_selection import train_test_split
from sklearn.cluster import KMeans
from sklearn.metrics import pairwise_distances_argmin_min, pairwise_distances
import pickle
import numpy as np
from openpyxl import Workbook
from real_datasets import load_dataset
from HSICNet.HSICFeatureNet import *
from HSICNet.HSICNet import *
from HSICNet.util import *
import gc
import torch

def load_models(dataset_name, X_tensor_tbx):

    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

    print(f"Applying HSICFeatureNetGumbelSparsemax on dataset: {dataset_name}")
    # with open('trained_models/hsicfeaturegumbelsparsemax_autos.pkl', 'rb') as f:
    with open('trained_models/hsicfeaturegumbelsparsemax_bike.pkl', 'rb') as f:
        # featuregumbelsparsemax_model = torch.load(f, map_location=torch.device('cpu'))
        # featuregumbelsparsemax_model = torch.load(f, map_location=device)
        featuregumbelsparsemax_model = pickle.load(f)
    featuregumbelsparsemax_model.eval()
    with torch.no_grad():  # Disable gradient computation
        hsic_fNET_gsp_weights, _ ,_ , _= featuregumbelsparsemax_model(X_tensor_tbx)
    HSICFGSP_selected_features = (hsic_fNET_gsp_weights > 1e-3).to(torch.int32)


    print(f"Applying HSICGumbelSparsemax on dataset: {dataset_name}")
    # with open('trained_models/hsicnetgumbelsparsemax_autos.pkl', 'rb') as f:
    with open('trained_models/hsicnetgumbelsparsemax_bike.pkl', 'rb') as f:
        gumbelsparsemax_model = pickle.load(f)
    gumbelsparsemax_model.eval()  # Set the model to evaluation mode
    with torch.no_grad():  # Disable gradient computation
            hsic_gsp_weights, _ ,_ = gumbelsparsemax_model(X_tensor_tbx)
    gumbelsparsemax_selected_features = (hsic_gsp_weights > 1e-3).to(torch.int32)

    # model_filename = f"trained_models/hsicnetgumbelsparsemax_{dataset_name}.pkl"

    feature_importances_new = [hsic_gsp_weights, hsic_fNET_gsp_weights]
    selected_features_new = [gumbelsparsemax_selected_features, HSICFGSP_selected_features]
    # Save feature_importances to a .pkl file
    with open('feature_importances_new.pkl', 'wb') as f:
            pickle.dump(feature_importances_new, f)

    with open('selected_features_new.pkl', 'wb') as f:
        pickle.dump(selected_features_new, f)

import os
print(os.getcwd())
!ls

def consistency_across_methods(feature_matrix, feature_importances_list, method_names, n_clusters=5):
    """
    Evaluate the consistency of feature importance values across similar (clustered) instances
    for multiple attribution methods.

    Parameters:
        feature_matrix (numpy.ndarray): Test data feature matrix of shape [n_instances, n_features].
                                         This represents input instances in feature space.
        feature_importances_list (list of numpy.ndarray): A list of feature importance matrices.
                                                          Each matrix corresponds to one method and has shape [n_instances, n_features].
        method_names (list of str): Names of the methods corresponding to the feature importance matrices.
        n_clusters (int): Number of clusters to group similar instances in feature space.

    Returns:
        consistency_scores (dict): A dictionary with method names as keys and their consistency scores
                                    (list of float scores for each cluster) as values.
    """
    feature_matrix = np.array(feature_matrix)  # Ensure feature_matrix is a NumPy array
    consistency_scores = {}

    for method_idx, (method_name, feature_importances) in enumerate(zip(method_names, feature_importances_list)):
        print(f"Evaluating consistency for method: {method_name}...")
        # feature_importances = np.array(feature_importances)  # Ensure importance matrix is a NumPy array
        feature_importances = feature_importances.cpu().numpy()
        # Perform clustering using K-Means
        kmeans = KMeans(n_clusters=n_clusters, random_state=42)
        cluster_labels = kmeans.fit_predict(feature_matrix)

        # Measure consistency within each cluster
        cluster_consistency = []

        for cluster_idx in range(n_clusters):
            # Indices of instances in the current cluster
            cluster_indices = np.where(cluster_labels == cluster_idx)[0]
            cluster_features = feature_matrix[cluster_indices]  # Features of instances in the cluster
            cluster_importances = feature_importances[cluster_indices]  # Importances of instances in the cluster

            # If the cluster has just one element, skip it
            if len(cluster_indices) <= 1:
                cluster_consistency.append(0)  # Small cluster, by definition consistent
                continue

            # 1. Compute pairwise distances between instances in the cluster (feature space)
            pairwise_feature_distances = pairwise_distances(cluster_features, metric='euclidean')

            # 2. Compute pairwise distances between feature importance vectors (importance space)
            pairwise_importance_distances = pairwise_distances(cluster_importances, metric='euclidean')

            # 3. Normalize importance distances by feature space distances (consistency measure)
            # Avoid division by zero in distances
            normalized_distances = np.divide(
                pairwise_importance_distances,
                pairwise_feature_distances + 1e-8  # Small epsilon to prevent division by zero
            )

            # Use mean normalized pairwise distance as the consistency score for this cluster
            cluster_consistency_score = np.mean(normalized_distances)
            cluster_consistency.append(cluster_consistency_score)

        # Store the consistency results for the current method
        consistency_scores[method_name] = cluster_consistency

    return consistency_scores

def save_consistency_scores_to_csv(consistency_scores, dataset_name, filename="consistency_scores.csv"):
    """
    Save consistency scores to a CSV file, including the dataset name.

    Parameters:
        consistency_scores (dict): A dictionary where keys are method names and values are lists of
                                    consistency scores for each cluster.
        dataset_name (str): The name of the dataset.
        filename (str): The name of the CSV file to save the results in.
    """
    # Prepare data for CSV
    data = []
    for method_name, scores in consistency_scores.items():
        for cluster_idx, score in enumerate(scores):
            # Create a row for each (method, cluster, score)
            data.append({
                "Dataset": dataset_name,
                "Method": method_name,
                "Cluster": cluster_idx + 1,
                "Consistency Score": score
            })

    # Convert to pandas DataFrame
    df = pd.DataFrame(data)

    # Save to a CSV file
    df.to_csv(filename, index=False)

    print(f"Consistency scores saved to {filename}.")

if __name__ == "__main__":

    print(torch.cuda.is_available())
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

    method_names = [
            'Hsic_GumbelSparsemax',
            'HSICFeatureNet_GumbelSparsemax'

        ]
    # dataset_names = ["breast_cancer", "sonar", "nomao", "steel", "breast_cancer_wisconsin", "skillcraft", "ionosphere", "sml", "pol", \
                        #  'parkinson', 'keggdirected', "pumadyn32nm", "crime", "gas", 'autos', 'bike', 'keggundirected']
    datasets= ['bike']
        # Main running part of the script
        # for dataset_name in dataset_names:
    for data in datasets:
        print(f"\nProcessing dataset: {data}")
        X, y = load_dataset(data)

        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=42)
        n, d = X_train.shape
        X_tensor= torch.tensor(X_test, dtype=torch.float32).to(device=device)
        sampleNo_tbx = 200

        load_models(data, X_tensor)
        with open('feature_importances_new.pkl', 'rb') as f:
            feature_importances = pickle.load(f)

        # Plot feature importances for 10 randomly selected instances
        # plot_feature_importances_matrix(feature_importances, method_names, num_instances=10)
    ##-------------------
    #2nd experiment
        # Evaluate consistency across methods
        n_clusters = 6  # Number of clusters to group similar instances
        consistency_scores = consistency_across_methods(X_test, feature_importances, method_names, n_clusters)

        # Output consistency scores for each method
        print("\nConsistency Scores (Lower is better):")
        for method_name, scores in consistency_scores.items():
            print(f"Method: {method_name}")
            for cluster_idx, score in enumerate(scores):
                print(f"  Cluster {cluster_idx + 1}: Consistency Score = {score:.20f}")


save_consistency_scores_to_csv(consistency_scores, data, filename="consistency_scores.csv")

!ls

from google.colab import files

# Download the CSS file
files.download('consistency_scores.csv')